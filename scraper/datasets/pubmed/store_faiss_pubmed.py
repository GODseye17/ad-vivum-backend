import faiss
import json
import numpy as np
from langchain.embeddings import HuggingFaceEmbeddings  # Use Hugging Face instead of OpenAI

# ğŸ”¹ Load scraped data
with open("datasets/pubmed/scraped_data_pubmed.json", "r") as f:
    articles = json.load(f)

# ğŸ”¹ Initialize Hugging Face Embeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ”¹ Convert articles to embeddings
article_texts = [article["abstract"] for article in articles if article["abstract"]]
if not article_texts:
    print("âš ï¸ No valid articles found! Exiting...")
    exit()

article_vectors = embeddings.embed_documents(article_texts)

# ğŸ”¹ Store vectors in FAISS
dimension = len(article_vectors[0])
index = faiss.IndexFlatL2(dimension)
index.add(np.array(article_vectors, dtype=np.float32))

# ğŸ”¹ Save FAISS index
faiss.write_index(index, "datasets/pubmed/news_index_pubmed.faiss")
print("âœ… FAISS index saved as news_index.faiss")
